{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d76b55e4",
   "metadata": {},
   "source": [
    "# Shap variance penalty\n",
    "\n",
    "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ing-bank/probatus/blob/master/docs/tutorials/nb_shap_variance_penalty_and_results_comparison.ipynb)\n",
    "\n",
    "When ShapRFECV is computing feature importance and subsequently eliminating features, it computes the average of shap values to get an estimate of that feature's overall importance. In some situations, the variance of these shap values might be high - which might indicate a lack of agreement regarding that feature's importance. Catering to this situation, probatus allows you to penalize features that have a higher variance of shap values.\n",
    "\n",
    "By setting `shap_variance_penalty_factor` param within `fit_compute()` method, the averaging of shap values is computed by:\n",
    "<<add>>\n",
    "\n",
    "See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fbf6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install probatus\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4037e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probatus.feature_elimination import ShapRFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50b0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=500, n_informative=20, n_features=100)\n",
    "model = CatBoostClassifier(n_estimators=100, verbose=0)\n",
    "shap_elimination = ShapRFECV(model=model, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1)\n",
    "report_with_penalty = shap_elimination.fit_compute(X, y, shap_variance_penalty_factor=1.0)\n",
    "report_without_penalty = shap_elimination.fit_compute(X, y, shap_variance_penalty_factor=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41bf725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_features</th>\n",
       "      <th>features_set</th>\n",
       "      <th>eliminated_features</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>train_metric_std</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>val_metric_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[48, 23, 25, 17, 41, 79, 70, 67, 96, 95, 52, 5...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783734</td>\n",
       "      <td>0.036136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[29, 44, 31, 80, 34, 42, 60, 87, 77, 75, 64, 7...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818636</td>\n",
       "      <td>0.027409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[63, 59, 83, 12, 38, 90, 93, 16, 49, 94, 8, 1]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.040263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>[0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 18, 19,...</td>\n",
       "      <td>[62, 14, 36, 18, 3, 4, 24, 74, 82, 89]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825634</td>\n",
       "      <td>0.027513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>[0, 2, 5, 9, 10, 11, 13, 15, 19, 20, 21, 22, 3...</td>\n",
       "      <td>[2, 66, 68, 39, 71, 72, 22, 99]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.858765</td>\n",
       "      <td>0.031187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>[0, 5, 9, 10, 11, 13, 15, 19, 20, 21, 30, 35, ...</td>\n",
       "      <td>[19, 69, 53, 30, 37, 15]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845318</td>\n",
       "      <td>0.034718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>[0, 5, 9, 10, 11, 13, 20, 21, 35, 40, 43, 45, ...</td>\n",
       "      <td>[21, 43, 98, 57, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847304</td>\n",
       "      <td>0.029020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>[5, 9, 10, 11, 13, 20, 35, 40, 45, 46, 47, 51,...</td>\n",
       "      <td>[45, 20, 84, 88]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863716</td>\n",
       "      <td>0.027382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>[5, 9, 10, 11, 13, 35, 40, 46, 47, 51, 54, 58,...</td>\n",
       "      <td>[13, 76, 92]</td>\n",
       "      <td>0.972956</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.035161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>[5, 9, 10, 11, 35, 40, 46, 47, 51, 54, 58, 65,...</td>\n",
       "      <td>[47, 51, 35]</td>\n",
       "      <td>0.969608</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.823234</td>\n",
       "      <td>0.055277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[5, 9, 10, 11, 40, 46, 54, 58, 65, 73, 81, 85,...</td>\n",
       "      <td>[46, 58]</td>\n",
       "      <td>0.962777</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.800052</td>\n",
       "      <td>0.048493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>[5, 9, 10, 11, 40, 54, 65, 73, 81, 85, 91]</td>\n",
       "      <td>[9, 91]</td>\n",
       "      <td>0.956023</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.814270</td>\n",
       "      <td>0.051047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>[5, 10, 11, 40, 54, 65, 73, 81, 85]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>0.951823</td>\n",
       "      <td>0.009062</td>\n",
       "      <td>0.804158</td>\n",
       "      <td>0.079721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>[5, 11, 40, 54, 65, 73, 81, 85]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.930154</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.770472</td>\n",
       "      <td>0.048131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>[11, 40, 54, 65, 73, 81, 85]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>0.906913</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.762450</td>\n",
       "      <td>0.029873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[11, 40, 54, 65, 73, 85]</td>\n",
       "      <td>[54]</td>\n",
       "      <td>0.894709</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.743937</td>\n",
       "      <td>0.029733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>[11, 40, 65, 73, 85]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.875344</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.725548</td>\n",
       "      <td>0.026652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_features                                       features_set  \\\n",
       "1            100  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2             80  [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3             64  [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "4             52  [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 18, 19,...   \n",
       "5             42  [0, 2, 5, 9, 10, 11, 13, 15, 19, 20, 21, 22, 3...   \n",
       "6             34  [0, 5, 9, 10, 11, 13, 15, 19, 20, 21, 30, 35, ...   \n",
       "7             28  [0, 5, 9, 10, 11, 13, 20, 21, 35, 40, 43, 45, ...   \n",
       "8             23  [5, 9, 10, 11, 13, 20, 35, 40, 45, 46, 47, 51,...   \n",
       "9             19  [5, 9, 10, 11, 13, 35, 40, 46, 47, 51, 54, 58,...   \n",
       "10            16  [5, 9, 10, 11, 35, 40, 46, 47, 51, 54, 58, 65,...   \n",
       "11            13  [5, 9, 10, 11, 40, 46, 54, 58, 65, 73, 81, 85,...   \n",
       "12            11         [5, 9, 10, 11, 40, 54, 65, 73, 81, 85, 91]   \n",
       "13             9                [5, 10, 11, 40, 54, 65, 73, 81, 85]   \n",
       "14             8                    [5, 11, 40, 54, 65, 73, 81, 85]   \n",
       "15             7                       [11, 40, 54, 65, 73, 81, 85]   \n",
       "16             6                           [11, 40, 54, 65, 73, 85]   \n",
       "17             5                               [11, 40, 65, 73, 85]   \n",
       "\n",
       "                                  eliminated_features  train_metric_mean  \\\n",
       "1   [48, 23, 25, 17, 41, 79, 70, 67, 96, 95, 52, 5...           1.000000   \n",
       "2   [29, 44, 31, 80, 34, 42, 60, 87, 77, 75, 64, 7...           1.000000   \n",
       "3      [63, 59, 83, 12, 38, 90, 93, 16, 49, 94, 8, 1]           1.000000   \n",
       "4              [62, 14, 36, 18, 3, 4, 24, 74, 82, 89]           1.000000   \n",
       "5                     [2, 66, 68, 39, 71, 72, 22, 99]           1.000000   \n",
       "6                            [19, 69, 53, 30, 37, 15]           1.000000   \n",
       "7                                 [21, 43, 98, 57, 0]           1.000000   \n",
       "8                                    [45, 20, 84, 88]           1.000000   \n",
       "9                                        [13, 76, 92]           0.972956   \n",
       "10                                       [47, 51, 35]           0.969608   \n",
       "11                                           [46, 58]           0.962777   \n",
       "12                                            [9, 91]           0.956023   \n",
       "13                                               [10]           0.951823   \n",
       "14                                                [5]           0.930154   \n",
       "15                                               [81]           0.906913   \n",
       "16                                               [54]           0.894709   \n",
       "17                                                 []           0.875344   \n",
       "\n",
       "    train_metric_std  val_metric_mean  val_metric_std  \n",
       "1           0.000000         0.783734        0.036136  \n",
       "2           0.000000         0.818636        0.027409  \n",
       "3           0.000000         0.809475        0.040263  \n",
       "4           0.000000         0.825634        0.027513  \n",
       "5           0.000000         0.858765        0.031187  \n",
       "6           0.000000         0.845318        0.034718  \n",
       "7           0.000000         0.847304        0.029020  \n",
       "8           0.000000         0.863716        0.027382  \n",
       "9           0.005839         0.815100        0.035161  \n",
       "10          0.003283         0.823234        0.055277  \n",
       "11          0.011050         0.800052        0.048493  \n",
       "12          0.008971         0.814270        0.051047  \n",
       "13          0.009062         0.804158        0.079721  \n",
       "14          0.008260         0.770472        0.048131  \n",
       "15          0.008914         0.762450        0.029873  \n",
       "16          0.009730         0.743937        0.029733  \n",
       "17          0.012642         0.725548        0.026652  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_with_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc62391",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_features</th>\n",
       "      <th>features_set</th>\n",
       "      <th>eliminated_features</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>train_metric_std</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>val_metric_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[48, 23, 25, 17, 41, 79, 70, 67, 96, 95, 52, 5...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783734</td>\n",
       "      <td>0.036136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[29, 44, 31, 80, 34, 42, 60, 87, 77, 75, 64, 7...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818636</td>\n",
       "      <td>0.027409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[63, 59, 83, 12, 38, 90, 93, 16, 49, 94, 8, 1]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.040263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>[0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 18, 19,...</td>\n",
       "      <td>[62, 14, 36, 18, 3, 4, 24, 74, 82, 89]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825634</td>\n",
       "      <td>0.027513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>[0, 2, 5, 9, 10, 11, 13, 15, 19, 20, 21, 22, 3...</td>\n",
       "      <td>[2, 66, 68, 39, 71, 72, 22, 99]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.858765</td>\n",
       "      <td>0.031187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>[0, 5, 9, 10, 11, 13, 15, 19, 20, 21, 30, 35, ...</td>\n",
       "      <td>[19, 69, 53, 30, 37, 15]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845318</td>\n",
       "      <td>0.034718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>[0, 5, 9, 10, 11, 13, 20, 21, 35, 40, 43, 45, ...</td>\n",
       "      <td>[21, 43, 98, 57, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847304</td>\n",
       "      <td>0.029020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>[5, 9, 10, 11, 13, 20, 35, 40, 45, 46, 47, 51,...</td>\n",
       "      <td>[45, 20, 84, 88]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863716</td>\n",
       "      <td>0.027382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>[5, 9, 10, 11, 13, 35, 40, 46, 47, 51, 54, 58,...</td>\n",
       "      <td>[13, 76, 92]</td>\n",
       "      <td>0.972956</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.035161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>[5, 9, 10, 11, 35, 40, 46, 47, 51, 54, 58, 65,...</td>\n",
       "      <td>[47, 51, 35]</td>\n",
       "      <td>0.969608</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.823234</td>\n",
       "      <td>0.055277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[5, 9, 10, 11, 40, 46, 54, 58, 65, 73, 81, 85,...</td>\n",
       "      <td>[46, 58]</td>\n",
       "      <td>0.962777</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.800052</td>\n",
       "      <td>0.048493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>[5, 9, 10, 11, 40, 54, 65, 73, 81, 85, 91]</td>\n",
       "      <td>[9, 91]</td>\n",
       "      <td>0.956023</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.814270</td>\n",
       "      <td>0.051047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>[5, 10, 11, 40, 54, 65, 73, 81, 85]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>0.951823</td>\n",
       "      <td>0.009062</td>\n",
       "      <td>0.804158</td>\n",
       "      <td>0.079721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>[5, 11, 40, 54, 65, 73, 81, 85]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.930154</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.770472</td>\n",
       "      <td>0.048131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>[11, 40, 54, 65, 73, 81, 85]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>0.906913</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.762450</td>\n",
       "      <td>0.029873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[11, 40, 54, 65, 73, 85]</td>\n",
       "      <td>[54]</td>\n",
       "      <td>0.894709</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.743937</td>\n",
       "      <td>0.029733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>[11, 40, 65, 73, 85]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.875344</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.725548</td>\n",
       "      <td>0.026652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[80, 4, 64, 33, 14, 87, 48, 36, 56, 6, 18, 29,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783734</td>\n",
       "      <td>0.036136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>[77, 19, 2, 31, 57, 86, 26, 37, 59, 68, 72, 63...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.826010</td>\n",
       "      <td>0.033883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>[0, 1, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, ...</td>\n",
       "      <td>[34, 15, 12, 83, 55, 8, 38, 75, 44, 53, 78, 69]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840406</td>\n",
       "      <td>0.004867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>[0, 1, 3, 5, 7, 9, 10, 11, 13, 16, 17, 20, 21,...</td>\n",
       "      <td>[17, 89, 93, 3, 23, 62, 60, 1, 49, 96]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834353</td>\n",
       "      <td>0.023681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>[0, 5, 7, 9, 10, 11, 13, 16, 20, 21, 22, 27, 2...</td>\n",
       "      <td>[43, 71, 0, 84, 7, 97, 98, 88]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845624</td>\n",
       "      <td>0.017201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>[5, 9, 10, 11, 13, 16, 20, 21, 22, 27, 28, 32,...</td>\n",
       "      <td>[90, 21, 16, 70, 27, 95]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863096</td>\n",
       "      <td>0.030650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>[5, 9, 10, 11, 13, 20, 22, 28, 32, 35, 40, 45,...</td>\n",
       "      <td>[28, 46, 61, 20, 94]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.036105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>[5, 9, 10, 11, 13, 22, 32, 35, 40, 45, 47, 51,...</td>\n",
       "      <td>[82, 32, 74, 13]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.858418</td>\n",
       "      <td>0.031434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>[5, 9, 10, 11, 22, 35, 40, 45, 47, 51, 54, 58,...</td>\n",
       "      <td>[92, 58, 35]</td>\n",
       "      <td>0.978937</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.857832</td>\n",
       "      <td>0.040339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>[5, 9, 10, 11, 22, 40, 45, 47, 51, 54, 65, 73,...</td>\n",
       "      <td>[47, 76, 91]</td>\n",
       "      <td>0.973436</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.856597</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[5, 9, 10, 11, 22, 40, 45, 51, 54, 65, 73, 81,...</td>\n",
       "      <td>[9, 45]</td>\n",
       "      <td>0.966317</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.836464</td>\n",
       "      <td>0.069308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>[5, 10, 11, 22, 40, 51, 54, 65, 73, 81, 85]</td>\n",
       "      <td>[11, 81]</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>0.826117</td>\n",
       "      <td>0.055609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>[5, 10, 22, 40, 51, 54, 65, 73, 85]</td>\n",
       "      <td>[51]</td>\n",
       "      <td>0.946004</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.066020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>[5, 10, 22, 40, 54, 65, 73, 85]</td>\n",
       "      <td>[22]</td>\n",
       "      <td>0.932403</td>\n",
       "      <td>0.010371</td>\n",
       "      <td>0.796027</td>\n",
       "      <td>0.049649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>[5, 10, 40, 54, 65, 73, 85]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.918967</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.054531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[10, 40, 54, 65, 73, 85]</td>\n",
       "      <td>[54]</td>\n",
       "      <td>0.905771</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.785010</td>\n",
       "      <td>0.050255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>[10, 40, 65, 73, 85]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.876856</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.725792</td>\n",
       "      <td>0.058888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_features                                       features_set  \\\n",
       "1            100  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2             80  [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3             64  [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "4             52  [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 18, 19,...   \n",
       "5             42  [0, 2, 5, 9, 10, 11, 13, 15, 19, 20, 21, 22, 3...   \n",
       "6             34  [0, 5, 9, 10, 11, 13, 15, 19, 20, 21, 30, 35, ...   \n",
       "7             28  [0, 5, 9, 10, 11, 13, 20, 21, 35, 40, 43, 45, ...   \n",
       "8             23  [5, 9, 10, 11, 13, 20, 35, 40, 45, 46, 47, 51,...   \n",
       "9             19  [5, 9, 10, 11, 13, 35, 40, 46, 47, 51, 54, 58,...   \n",
       "10            16  [5, 9, 10, 11, 35, 40, 46, 47, 51, 54, 58, 65,...   \n",
       "11            13  [5, 9, 10, 11, 40, 46, 54, 58, 65, 73, 81, 85,...   \n",
       "12            11         [5, 9, 10, 11, 40, 54, 65, 73, 81, 85, 91]   \n",
       "13             9                [5, 10, 11, 40, 54, 65, 73, 81, 85]   \n",
       "14             8                    [5, 11, 40, 54, 65, 73, 81, 85]   \n",
       "15             7                       [11, 40, 54, 65, 73, 81, 85]   \n",
       "16             6                           [11, 40, 54, 65, 73, 85]   \n",
       "17             5                               [11, 40, 65, 73, 85]   \n",
       "1            100  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2             80  [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 1...   \n",
       "3             64  [0, 1, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, ...   \n",
       "4             52  [0, 1, 3, 5, 7, 9, 10, 11, 13, 16, 17, 20, 21,...   \n",
       "5             42  [0, 5, 7, 9, 10, 11, 13, 16, 20, 21, 22, 27, 2...   \n",
       "6             34  [5, 9, 10, 11, 13, 16, 20, 21, 22, 27, 28, 32,...   \n",
       "7             28  [5, 9, 10, 11, 13, 20, 22, 28, 32, 35, 40, 45,...   \n",
       "8             23  [5, 9, 10, 11, 13, 22, 32, 35, 40, 45, 47, 51,...   \n",
       "9             19  [5, 9, 10, 11, 22, 35, 40, 45, 47, 51, 54, 58,...   \n",
       "10            16  [5, 9, 10, 11, 22, 40, 45, 47, 51, 54, 65, 73,...   \n",
       "11            13  [5, 9, 10, 11, 22, 40, 45, 51, 54, 65, 73, 81,...   \n",
       "12            11        [5, 10, 11, 22, 40, 51, 54, 65, 73, 81, 85]   \n",
       "13             9                [5, 10, 22, 40, 51, 54, 65, 73, 85]   \n",
       "14             8                    [5, 10, 22, 40, 54, 65, 73, 85]   \n",
       "15             7                        [5, 10, 40, 54, 65, 73, 85]   \n",
       "16             6                           [10, 40, 54, 65, 73, 85]   \n",
       "17             5                               [10, 40, 65, 73, 85]   \n",
       "\n",
       "                                  eliminated_features  train_metric_mean  \\\n",
       "1   [48, 23, 25, 17, 41, 79, 70, 67, 96, 95, 52, 5...           1.000000   \n",
       "2   [29, 44, 31, 80, 34, 42, 60, 87, 77, 75, 64, 7...           1.000000   \n",
       "3      [63, 59, 83, 12, 38, 90, 93, 16, 49, 94, 8, 1]           1.000000   \n",
       "4              [62, 14, 36, 18, 3, 4, 24, 74, 82, 89]           1.000000   \n",
       "5                     [2, 66, 68, 39, 71, 72, 22, 99]           1.000000   \n",
       "6                            [19, 69, 53, 30, 37, 15]           1.000000   \n",
       "7                                 [21, 43, 98, 57, 0]           1.000000   \n",
       "8                                    [45, 20, 84, 88]           1.000000   \n",
       "9                                        [13, 76, 92]           0.972956   \n",
       "10                                       [47, 51, 35]           0.969608   \n",
       "11                                           [46, 58]           0.962777   \n",
       "12                                            [9, 91]           0.956023   \n",
       "13                                               [10]           0.951823   \n",
       "14                                                [5]           0.930154   \n",
       "15                                               [81]           0.906913   \n",
       "16                                               [54]           0.894709   \n",
       "17                                                 []           0.875344   \n",
       "1   [80, 4, 64, 33, 14, 87, 48, 36, 56, 6, 18, 29,...           1.000000   \n",
       "2   [77, 19, 2, 31, 57, 86, 26, 37, 59, 68, 72, 63...           1.000000   \n",
       "3     [34, 15, 12, 83, 55, 8, 38, 75, 44, 53, 78, 69]           1.000000   \n",
       "4              [17, 89, 93, 3, 23, 62, 60, 1, 49, 96]           1.000000   \n",
       "5                      [43, 71, 0, 84, 7, 97, 98, 88]           1.000000   \n",
       "6                            [90, 21, 16, 70, 27, 95]           1.000000   \n",
       "7                                [28, 46, 61, 20, 94]           1.000000   \n",
       "8                                    [82, 32, 74, 13]           1.000000   \n",
       "9                                        [92, 58, 35]           0.978937   \n",
       "10                                       [47, 76, 91]           0.973436   \n",
       "11                                            [9, 45]           0.966317   \n",
       "12                                           [11, 81]           0.958512   \n",
       "13                                               [51]           0.946004   \n",
       "14                                               [22]           0.932403   \n",
       "15                                                [5]           0.918967   \n",
       "16                                               [54]           0.905771   \n",
       "17                                                 []           0.876856   \n",
       "\n",
       "    train_metric_std  val_metric_mean  val_metric_std  \n",
       "1           0.000000         0.783734        0.036136  \n",
       "2           0.000000         0.818636        0.027409  \n",
       "3           0.000000         0.809475        0.040263  \n",
       "4           0.000000         0.825634        0.027513  \n",
       "5           0.000000         0.858765        0.031187  \n",
       "6           0.000000         0.845318        0.034718  \n",
       "7           0.000000         0.847304        0.029020  \n",
       "8           0.000000         0.863716        0.027382  \n",
       "9           0.005839         0.815100        0.035161  \n",
       "10          0.003283         0.823234        0.055277  \n",
       "11          0.011050         0.800052        0.048493  \n",
       "12          0.008971         0.814270        0.051047  \n",
       "13          0.009062         0.804158        0.079721  \n",
       "14          0.008260         0.770472        0.048131  \n",
       "15          0.008914         0.762450        0.029873  \n",
       "16          0.009730         0.743937        0.029733  \n",
       "17          0.012642         0.725548        0.026652  \n",
       "1           0.000000         0.783734        0.036136  \n",
       "2           0.000000         0.826010        0.033883  \n",
       "3           0.000000         0.840406        0.004867  \n",
       "4           0.000000         0.834353        0.023681  \n",
       "5           0.000000         0.845624        0.017201  \n",
       "6           0.000000         0.863096        0.030650  \n",
       "7           0.000000         0.856743        0.036105  \n",
       "8           0.000000         0.858418        0.031434  \n",
       "9           0.004357         0.857832        0.040339  \n",
       "10          0.004632         0.856597        0.044714  \n",
       "11          0.006283         0.836464        0.069308  \n",
       "12          0.007243         0.826117        0.055609  \n",
       "13          0.011688         0.807256        0.066020  \n",
       "14          0.010371         0.796027        0.049649  \n",
       "15          0.005895         0.797665        0.054531  \n",
       "16          0.006757         0.785010        0.050255  \n",
       "17          0.006382         0.725792        0.058888  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_without_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3bdfca",
   "metadata": {},
   "source": [
    "# Which approach is better?\n",
    "\n",
    "Let's compare a few different configurations of RFECV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e41b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score_a</th>\n",
       "      <th>std_a</th>\n",
       "      <th>num_features_a</th>\n",
       "      <th>best_score_b</th>\n",
       "      <th>std_b</th>\n",
       "      <th>num_features_b</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_informative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892217</td>\n",
       "      <td>0.028543</td>\n",
       "      <td>8</td>\n",
       "      <td>0.894579</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>20</td>\n",
       "      <td>188</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.797291</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>24</td>\n",
       "      <td>0.801302</td>\n",
       "      <td>0.040278</td>\n",
       "      <td>36</td>\n",
       "      <td>404</td>\n",
       "      <td>200</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741265</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>29</td>\n",
       "      <td>0.701914</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>54</td>\n",
       "      <td>499</td>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786747</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>8</td>\n",
       "      <td>0.787802</td>\n",
       "      <td>0.065435</td>\n",
       "      <td>24</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.834444</td>\n",
       "      <td>0.067287</td>\n",
       "      <td>7</td>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.091079</td>\n",
       "      <td>5</td>\n",
       "      <td>176</td>\n",
       "      <td>200</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_score_a     std_a  num_features_a  best_score_b     std_b  \\\n",
       "0      0.892217  0.028543               8      0.894579  0.013364   \n",
       "1      0.797291  0.036200              24      0.801302  0.040278   \n",
       "2      0.741265  0.021340              29      0.701914  0.028287   \n",
       "3      0.786747  0.087275               8      0.787802  0.065435   \n",
       "4      0.834444  0.067287               7      0.770303  0.091079   \n",
       "\n",
       "   num_features_b  n_samples  n_features  n_informative  \n",
       "0              20        188         200             13  \n",
       "1              36        404         200            141  \n",
       "2              54        499         200            180  \n",
       "3              24        179         200            183  \n",
       "4               5        176         200            198  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare A: shap_variance_penalty_factor=0.5 & approximate=True\n",
    "# vs B: shap_variance_penalty_factor=0 (disabled) & approximate=True\n",
    "num_simulations = 5\n",
    "results = []\n",
    "\n",
    "\n",
    "def get_best_idx(shap_report):\n",
    "    shap_report[\"eval_metric\"] = shap_report[\"val_metric_mean\"]\n",
    "    best_iteration_idx = shap_report[\"eval_metric\"].argmax()\n",
    "\n",
    "    return best_iteration_idx\n",
    "\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    # Params\n",
    "    n_samples = np.random.randint(100, 500)\n",
    "    n_features = 200\n",
    "    n_informative = np.random.randint(10, 200)\n",
    "    test_size = np.random.uniform(0.05, 0.5)\n",
    "\n",
    "    # Create data\n",
    "    X, y = make_classification(n_samples=n_samples, n_informative=n_informative, n_features=n_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # Model\n",
    "    model = CatBoostClassifier(n_estimators=100, verbose=0)\n",
    "\n",
    "    # Best score from ShapRFECV WITHOUT penalization\n",
    "    shap_elimination = ShapRFECV(\n",
    "        model=model, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1\n",
    "    )\n",
    "    report_a = shap_elimination.fit_compute(\n",
    "        X_train, y_train, shap_variance_penalty_factor=0, approximate=True, check_additivity=False\n",
    "    )\n",
    "    best_idx_a = get_best_idx(report_a)\n",
    "    best_score_a = report_a[\"val_metric_mean\"].iloc[best_idx_a]\n",
    "    std_a = report_a[\"val_metric_std\"].iloc[best_idx_a]\n",
    "    num_features_a = report_a[\"num_features\"].iloc[best_idx_a]\n",
    "\n",
    "    # Best score from ShapRFECV WITH penalization\n",
    "    shap_elimination = ShapRFECV(\n",
    "        model=model, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1\n",
    "    )\n",
    "    report_b = shap_elimination.fit_compute(\n",
    "        X_train, y_train, shap_variance_penalty_factor=0.5, approximate=True, check_additivity=False\n",
    "    )\n",
    "    best_idx_b = get_best_idx(report_b)\n",
    "    best_score_b = report_b[\"val_metric_mean\"].iloc[best_idx_b]\n",
    "    std_b = report_b[\"val_metric_std\"].iloc[best_idx_b]\n",
    "    num_features_b = report_b[\"num_features\"].iloc[best_idx_b]\n",
    "\n",
    "    results.append(\n",
    "        [best_score_a, std_a, num_features_a, best_score_b, std_b, num_features_b, n_samples, n_features, n_informative]\n",
    "    )\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\n",
    "            \"best_score_a\",\n",
    "            \"std_a\",\n",
    "            \"num_features_a\",\n",
    "            \"best_score_b\",\n",
    "            \"std_b\",\n",
    "            \"num_features_b\",\n",
    "            \"n_samples\",\n",
    "            \"n_features\",\n",
    "            \"n_informative\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9fb4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score_a</th>\n",
       "      <th>std_a</th>\n",
       "      <th>num_features_a</th>\n",
       "      <th>best_score_b</th>\n",
       "      <th>std_b</th>\n",
       "      <th>num_features_b</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_informative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.742664</td>\n",
       "      <td>0.091943</td>\n",
       "      <td>11</td>\n",
       "      <td>0.773073</td>\n",
       "      <td>0.095611</td>\n",
       "      <td>13</td>\n",
       "      <td>250</td>\n",
       "      <td>200</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829656</td>\n",
       "      <td>0.052365</td>\n",
       "      <td>20</td>\n",
       "      <td>0.798127</td>\n",
       "      <td>0.053808</td>\n",
       "      <td>29</td>\n",
       "      <td>327</td>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.724558</td>\n",
       "      <td>0.043146</td>\n",
       "      <td>83</td>\n",
       "      <td>0.746103</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>20</td>\n",
       "      <td>394</td>\n",
       "      <td>200</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822537</td>\n",
       "      <td>0.044845</td>\n",
       "      <td>36</td>\n",
       "      <td>0.825153</td>\n",
       "      <td>0.038366</td>\n",
       "      <td>29</td>\n",
       "      <td>479</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.729214</td>\n",
       "      <td>0.038897</td>\n",
       "      <td>83</td>\n",
       "      <td>0.731563</td>\n",
       "      <td>0.024997</td>\n",
       "      <td>54</td>\n",
       "      <td>485</td>\n",
       "      <td>200</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_score_a     std_a  num_features_a  best_score_b     std_b  \\\n",
       "0      0.742664  0.091943              11      0.773073  0.095611   \n",
       "1      0.829656  0.052365              20      0.798127  0.053808   \n",
       "2      0.724558  0.043146              83      0.746103  0.022388   \n",
       "3      0.822537  0.044845              36      0.825153  0.038366   \n",
       "4      0.729214  0.038897              83      0.731563  0.024997   \n",
       "\n",
       "   num_features_b  n_samples  n_features  n_informative  \n",
       "0              13        250         200             43  \n",
       "1              29        327         200             24  \n",
       "2              20        394         200            179  \n",
       "3              29        479         200             60  \n",
       "4              54        485         200            176  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare A: shap_variance_penalty_factor=0.5 & approximate=False\n",
    "# vs B: shap_variance_penalty_factor=0 (disabled) & approximate=False\n",
    "num_simulations = 5\n",
    "results = []\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    # Params\n",
    "    n_samples = np.random.randint(100, 500)\n",
    "    n_features = 200\n",
    "    n_informative = np.random.randint(10, 200)\n",
    "    test_size = np.random.uniform(0.05, 0.5)\n",
    "\n",
    "    # Create data\n",
    "    X, y = make_classification(n_samples=n_samples, n_informative=n_informative, n_features=n_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # Model\n",
    "    model = CatBoostClassifier(n_estimators=100, verbose=0)\n",
    "\n",
    "    # Best score from ShapRFECV WITHOUT penalization\n",
    "    shap_elimination = ShapRFECV(\n",
    "        model=model, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1\n",
    "    )\n",
    "    report_a = shap_elimination.fit_compute(X_train, y_train, shap_variance_penalty_factor=0, approximate=False)\n",
    "    best_idx_a = get_best_idx(report_a)\n",
    "    best_score_a = report_a[\"val_metric_mean\"].iloc[best_idx_a]\n",
    "    std_a = report_a[\"val_metric_std\"].iloc[best_idx_a]\n",
    "    num_features_a = report_a[\"num_features\"].iloc[best_idx_a]\n",
    "\n",
    "    # Best score from ShapRFECV WITH penalization\n",
    "    shap_elimination = ShapRFECV(\n",
    "        model=model, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1\n",
    "    )\n",
    "    report_b = shap_elimination.fit_compute(X_train, y_train, shap_variance_penalty_factor=0.5, approximate=False)\n",
    "    best_idx_b = get_best_idx(report_b)\n",
    "    best_score_b = report_b[\"val_metric_mean\"].iloc[best_idx_b]\n",
    "    std_b = report_b[\"val_metric_std\"].iloc[best_idx_b]\n",
    "    num_features_b = report_b[\"num_features\"].iloc[best_idx_b]\n",
    "\n",
    "    results.append(\n",
    "        [best_score_a, std_a, num_features_a, best_score_b, std_b, num_features_b, n_samples, n_features, n_informative]\n",
    "    )\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\n",
    "            \"best_score_a\",\n",
    "            \"std_a\",\n",
    "            \"num_features_a\",\n",
    "            \"best_score_b\",\n",
    "            \"std_b\",\n",
    "            \"num_features_b\",\n",
    "            \"n_samples\",\n",
    "            \"n_features\",\n",
    "            \"n_informative\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probatus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
